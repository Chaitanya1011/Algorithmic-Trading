{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Magic Score</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used requests and BeautifulSoup library to carry out web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used Dow Jones index components as the universe of stocks. This is not the right approach, becuse they do contain a few finance companied which are to be excluded in the universe of stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=[]\n",
    "for p in range(1,3):\n",
    "    url = 'https://money.cnn.com/data/markets/dow/?page='+str(p)\n",
    "    page = requests.get(url)\n",
    "    page_content = page.content\n",
    "    soup = BeautifulSoup(page_content,'html.parser') \n",
    "    tabl = soup.find_all(\"table\", {\"class\" : 'wsod_dataTable wsod_dataTableBig'})\n",
    "    for t in tabl:\n",
    "        rows = t.find_all(\"a\", {\"class\" : 'wsod_symbol'})\n",
    "        for row in rows:\n",
    "            name=(row.get_text()).split()\n",
    "            tickers.append(name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have extracted data from Yahoo Finance using web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_dir_curr = {} \n",
    "financial_dir_py = {} \n",
    "financial_dir_py2 = {} \n",
    "financial_dir_py3 = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping financial statement data for  MMM\n",
      "scraping financial statement data for  AXP\n",
      "scraping financial statement data for  AAPL\n",
      "scraping financial statement data for  BA\n",
      "scraping financial statement data for  CAT\n",
      "scraping financial statement data for  CVX\n",
      "scraping financial statement data for  CSCO\n",
      "scraping financial statement data for  KO\n",
      "scraping financial statement data for  DIS\n",
      "scraping financial statement data for  DOW\n",
      "Problem scraping data for  DOW\n",
      "scraping financial statement data for  XOM\n",
      "scraping financial statement data for  GS\n",
      "scraping financial statement data for  HD\n",
      "scraping financial statement data for  IBM\n",
      "scraping financial statement data for  INTC\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    try:\n",
    "        print(\"scraping financial statement data for \",ticker)\n",
    "        temp_dir = {}\n",
    "        temp_dir2 = {}\n",
    "        temp_dir3 = {}\n",
    "        temp_dir4 = {}\n",
    "    #getting balance sheet data from yahoo finance \n",
    "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/balance-sheet?p='+ticker\n",
    "#         print(url)\n",
    "        page = requests.get(url)\n",
    "        page_content = page.content\n",
    "        soup = BeautifulSoup(page_content,'html.parser')\n",
    "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "        for t in tabl:\n",
    "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "            for row in rows:\n",
    "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
    "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3]\n",
    "                temp_dir4[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[4]\n",
    "        \n",
    "        #getting income statement data from yahoo finance \n",
    "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/financials?p='+ticker\n",
    "#         print(url)\n",
    "        page = requests.get(url)\n",
    "        page_content = page.content\n",
    "        soup = BeautifulSoup(page_content,'html.parser')\n",
    "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "        for t in tabl:\n",
    "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "            for row in rows:\n",
    "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
    "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3]\n",
    "                temp_dir4[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[4]\n",
    "\n",
    "        \n",
    "        #getting cashflow statement data from yahoo finance \n",
    "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/cash-flow?p='+ticker\n",
    "        page = requests.get(url)\n",
    "#         print(url)\n",
    "        page_content = page.content\n",
    "        soup = BeautifulSoup(page_content,'html.parser')\n",
    "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
    "        for t in tabl:\n",
    "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
    "            for row in rows:\n",
    "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
    "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
    "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3] \n",
    "                temp_dir4[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[4] \n",
    "                \n",
    " #getting key statistics data from yahoo finance\n",
    "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/key-statistics?p='+ticker\n",
    "        page = requests.get(url)\n",
    "        page_content = page.content\n",
    "        soup = BeautifulSoup(page_content,'html.parser')\n",
    "        tabl = soup.find_all(\"table\", {\"class\" : \"W(100%) Bdcl(c)\"}) \n",
    "        for t in tabl:\n",
    "            rows = t.find_all(\"tr\", {\"class\" : \"Bxz(bb) H(36px) BdY Bdc($seperatorColor)\"}) +  t.find_all(\"tr\", {\"class\" : \"Bxz(bb) H(36px) BdB Bdbc($seperatorColor)\"}) + t.find_all(\"tr\", {\"class\" : \"Bxz(bb) H(36px) BdY Bdc($seperatorColor) fi-row Bgc($hoverBgColor):h\"}) +  t.find_all(\"tr\", {\"class\" : \"Bxz(bb) H(36px) BdB Bdbc($seperatorColor) fi-row Bgc($hoverBgColor):h\"})\n",
    "            for row in rows:\n",
    "                    temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[-1]    \n",
    "        \n",
    "        financial_dir_curr[ticker] = temp_dir\n",
    "        financial_dir_py[ticker] = temp_dir2\n",
    "        financial_dir_py2[ticker] = temp_dir3\n",
    "        financial_dir_py3[ticker] = temp_dir4\n",
    "    except:\n",
    "        print(\"Problem scraping data for \",ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had saved the data in directory. Below, I have saved the directory into Pandas Dataframe. <br>\n",
    "There is also a possibility that data of few tickers might not have been imported and hence I am updating the tickers list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_financials_curr = pd.DataFrame(financial_dir_curr)\n",
    "combined_financials_py = pd.DataFrame(financial_dir_py)\n",
    "combined_financials_py2 = pd.DataFrame(financial_dir_py2)\n",
    "combined_financials_py3 = pd.DataFrame(financial_dir_py3)\n",
    "tickers = combined_financials_curr.columns \n",
    "index = combined_financials_curr.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have saved the name of different financial data we have scraped in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = combined_financials_curr.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had extracted a lot of data, but we only need a few specific details and hence I have compiled them in a dataframe below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [\"Earnings before interest and taxes\",\n",
    "         \"Market cap (intra-day)\",\n",
    "         \"Net income applicable to common shares\",\n",
    "         \"Total cash flow from operating activities\",\n",
    "         \"Capital expenditure\",\n",
    "         \"Total current assets\",\n",
    "         \"Total current liabilities\",\n",
    "         \"Property plant and equipment\",\n",
    "         \"Total stockholder equity\",\n",
    "         \"Long-term debt\",\n",
    "         \"Enterprise value\",\n",
    "         \"Forward annual dividend yield\"] \n",
    "\n",
    "indx = [\"EBIT\",\"MarketCap\",\"NetIncome\",\"CashFlowOps\",\"Capex\",\"CurrAsset\",\n",
    "        \"CurrLiab\",\"PPE\",\"BookValue\",\"TotDebt\",\"TEV\",\"DivYield\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a possibilty that the name in the target dataframe might not match the extracted dataframe and hence I am checking for that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stats:\n",
    "    if i not in index:\n",
    "        print( i + \": Error, check row name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [\"Operating income or loss\",\n",
    "         \"Market cap (intra-day)\",\n",
    "         \"Net income available to common shareholders\",\n",
    "         \"Net cash provided by operating activities\",\n",
    "         \"Capital expenditure\",\n",
    "         \"Total current assets\",\n",
    "         \"Total current liabilities\",\n",
    "         \"Net property, plant and equipment\",\n",
    "         \"Total stockholders' equity\",\n",
    "         \"Long-term debt\",\n",
    "         \"Enterprise value\",\n",
    "         \"Forward annual dividend yield\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stats:\n",
    "    if i not in index:\n",
    "        print( i + \": Error, check row name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = {}\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "#         print(ticker)\n",
    "        temp = combined_financials_curr[ticker]\n",
    "#         print(temp)\n",
    "        ticker_stats = []\n",
    "        for stat in stats:\n",
    "#             print(temp.loc[stat])\n",
    "            ticker_stats.append(temp.loc[stat])\n",
    "        all_stats['{}'.format(ticker)] = ticker_stats\n",
    "    except:\n",
    "        print(\"can't read data for \",ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_df = pd.DataFrame(all_stats,index=indx)\n",
    "all_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataframe, many values are stored are in terms on B,M,T and % notation. Therefore below I have converted those colmuns into integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=all_stats_df.iloc[1,:].values\n",
    "y=all_stats_df.iloc[-2,:].values\n",
    "z=all_stats_df.iloc[-1,:].values\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> If ‘raise’, then invalid parsing will raise an exception\n",
    "-> If ‘coerce’, then invalid parsing will be set as NaN\n",
    "-> If ‘ignore’, then invalid parsing will return the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in x:\n",
    "    j=\"nan\"\n",
    "    if \"M\" in str(i):\n",
    "        j=str(i).replace(\"M\",\"e+03\")\n",
    "    if \"B\" in str(i):\n",
    "        j=str(i).replace(\"B\",\"e+06\")\n",
    "    if \"T\" in str(i):\n",
    "        j=str(i).replace(\"T\",\"e+09\")\n",
    "    if j!=\"nan\":\n",
    "        k=j.split(\"e+\")\n",
    "        p=int(k[1])\n",
    "        q=float(k[0])\n",
    "        j=q*pow(10,p)\n",
    "        a.append(int(j))\n",
    "    else:\n",
    "        a.append(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[]\n",
    "for i in y:\n",
    "    j=\"nan\"\n",
    "    if \"M\" in str(i):\n",
    "        j=str(i).replace(\"M\",\"e+03\")\n",
    "    if \"B\" in str(i):\n",
    "        j=str(i).replace(\"B\",\"e+06\")\n",
    "    if \"T\" in str(i):\n",
    "        j=str(i).replace(\"T\",\"e+09\")\n",
    "    if j!=\"nan\":\n",
    "        k=j.split(\"e+\")\n",
    "        p=int(k[1])\n",
    "        q=float(k[0])\n",
    "        j=q*pow(10,p)\n",
    "        b.append(int(j))\n",
    "    else:\n",
    "        b.append(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[]\n",
    "for i in z:\n",
    "    j=\"N/A\"\n",
    "    j=str(i).replace(\"%\",\"e-02\")\n",
    "    if j!=\"N/A\" and j!=\"nan\":\n",
    "        k=j.split(\"e\")\n",
    "        p=int(k[1])\n",
    "        q=float(k[0])\n",
    "        j=q*pow(10,p)\n",
    "        c.append(j)\n",
    "    else:\n",
    "        c.append(\"nan\")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_df.iloc[1,:]=a\n",
    "all_stats_df.iloc[-2,:]=b\n",
    "all_stats_df.iloc[-1,:]=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_df[tickers] = all_stats_df[tickers].replace({',': ''}, regex=True) \n",
    "for ticker in all_stats_df.columns:\n",
    "    all_stats_df[ticker] = pd.to_numeric(all_stats_df[ticker].values,errors='coerce',downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Magic Formula "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magic Formula is based on identifying wonderful stocks at bargain price.\n",
    "It is usually applied to large cap stocks, financial and insurance companies are excluded coz their balance sheet is altogether different.\n",
    "We rank companies based on Earning Yield and Return on Capital(ROC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have calculated all the values that we might require during magic score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_df = all_stats_df.transpose()\n",
    "final_stats_df = pd.DataFrame()\n",
    "final_stats_df[\"EBIT\"] = transpose_df[\"EBIT\"]\n",
    "final_stats_df[\"TEV\"] =  transpose_df[\"TEV\"]\n",
    "# final_stats_df[\"TEV\"] =  transpose_df[\"MarketCap\"].fillna(0) \\\n",
    "#                          +transpose_df[\"TotDebt\"].fillna(0) \\\n",
    "#                          +transpose_df[\"PrefStock\"].fillna(0) \\\n",
    "#                          +transpose_df[\"MinInterest\"].fillna(0) \\\n",
    "#                          -(transpose_df[\"CurrAsset\"].fillna(0)-transpose_df[\"CurrLiab\"].fillna(0))\n",
    "final_stats_df[\"EarningYield\"] =  final_stats_df[\"EBIT\"]/final_stats_df[\"TEV\"]\n",
    "# final_stats_df[\"FCFYield\"] = (transpose_df[\"CashFlowOps\"]-transpose_df[\"Capex\"])/transpose_df[\"MarketCap\"]\n",
    "final_stats_df[\"ROC\"]  = transpose_df[\"EBIT\"]/(transpose_df[\"PPE\"]+transpose_df[\"CurrAsset\"]-transpose_df[\"CurrLiab\"])\n",
    "# final_stats_df[\"BookToMkt\"] = transpose_df[\"BookValue\"]/transpose_df[\"MarketCap\"]\n",
    "# final_stats_df[\"DivYield\"] = transpose_df[\"DivYield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic Formula Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stats_val_df = final_stats_df.loc[tickers,:]\n",
    "final_stats_val_df[\"CombRank\"] = final_stats_val_df[\"EarningYield\"].rank(ascending=False,na_option='bottom')+final_stats_val_df[\"ROC\"].rank(ascending=False,na_option='bottom')\n",
    "final_stats_val_df[\"MagicFormulaRank\"] = final_stats_val_df[\"CombRank\"].rank(method='first')\n",
    "value_stocks = final_stats_val_df.sort_values(\"MagicFormulaRank\").iloc[:,[2,4,8]]\n",
    "print(value_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest Divident Yield Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_dividend_stocks = final_stats_df.sort_values(\"DivYield\",ascending=False).iloc[:,6]\n",
    "# print(high_dividend_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic Formula & Dividend yield combined Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_stats_df[\"CombRank\"] = final_stats_df[\"EarningYield\"].rank(ascending=False,method='first') \\\n",
    "#                               +final_stats_df[\"ROC\"].rank(ascending=False,method='first')  \\\n",
    "#                               +final_stats_df[\"DivYield\"].rank(ascending=False,method='first')\n",
    "# final_stats_df[\"CombinedRank\"] = final_stats_df[\"CombRank\"].rank(method='first')\n",
    "# value_high_div_stocks = final_stats_df.sort_values(\"CombinedRank\").iloc[:,[2,4,6,8]]\n",
    "# print(value_high_div_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People who invest via this strategy wait for a year to rebalance, they sell the losing stocks usually a week before the year ends to take advantage of the income tax provision that allows investors to use losses to offset their gains. They sell the winning stocks after the one-year, in order to take advantage of reduced income tax rates on long-term capital gains"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
